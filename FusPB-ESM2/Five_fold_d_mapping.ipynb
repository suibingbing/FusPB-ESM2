{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5219a3-6a26-4ee5-a9eb-1475fd87aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import random\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa444a-81b7-4d4c-afb2-cf7235e1bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model settings\n",
    "batch_size = 32  # Setting batchsize\n",
    "learning_rates=0.000065 # Setting learning rates\n",
    "d_m=\"1024_480\"#Selecting the dimension mapping method: 480_1024, 480_1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a0c2b-53c4-444c-8cb5-2ac35622390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset definitions\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.sequence, self.label = self.read_file(file)\n",
    "        self.sequence_protbert=self.add_space_between_characters(self.sequence)\n",
    "\n",
    "    def read_file(self,file_path):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        with open(file_path, 'r', newline='') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            next(csv_reader, None)  \n",
    "            data = list(csv_reader)\n",
    "            random.seed(42)\n",
    "            random.shuffle(data)\n",
    "            for row in data:\n",
    "                sequences.append(row[0])\n",
    "                labels.append(row[1])\n",
    "        return sequences, labels\n",
    "    \n",
    "    def add_space_between_characters(self,input_list):\n",
    "        new_list = []\n",
    "        for element in input_list:\n",
    "            new_element = ' '.join(element)\n",
    "            new_list.append(new_element)\n",
    "        return new_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample=self.sequence[index]\n",
    "        sample_protbert=self.sequence_protbert[index]\n",
    "        label=int(self.label[index])\n",
    "        return sample, label, sample_protbert\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd34649-fa6c-41eb-b003-cda0e4f174d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training set\n",
    "\n",
    "train_file = 'data/trainCPP.csv'  \n",
    "train_dataset = MyDataset(train_file)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda0fa8-ce8b-4210-84de-dbd6c7949801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the fusion models:1024_480\n",
    "\n",
    "class MyModel1(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(MyModel1, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "        self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "        self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc_pro = nn.Linear(1024, 480)  \n",
    "        self.fc1 = nn.Linear(480, 2)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(20, 2)  \n",
    "\n",
    "    def forward(self, inputs,inputs2):\n",
    "        inputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        encoded_input = self.tokenizer_pro(inputs2, padding=True, truncation=True,return_tensors='pt').to(device)\n",
    "        outputs_pro = self.model_pro(**encoded_input)\n",
    "        pooler_output1 = outputs.pooler_output   \n",
    "        pooler_output2=outputs_pro.pooler_output\n",
    "        pooler_output2=self.fc_pro(pooler_output2)\n",
    "        x =pooler_output1+pooler_output2\n",
    "        x=self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b89d0-d3fe-4a52-bbcd-641e5ce00a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the fusion models:480_1024\n",
    "\n",
    "class MyModel2(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(MyModel2, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "        self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "        self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc_pro = nn.Linear(480, 1024)  \n",
    "        self.fc1 = nn.Linear(1024, 2)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(20, 2)  \n",
    "\n",
    "    def forward(self, inputs,inputs2):\n",
    "        inputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        encoded_input = self.tokenizer_pro(inputs2, padding=True, truncation=True,return_tensors='pt').to(device)\n",
    "        outputs_pro = self.model_pro(**encoded_input)\n",
    "        pooler_output1 = outputs.pooler_output   \n",
    "        pooler_output2=outputs_pro.pooler_output\n",
    "        pooler_output1=self.fc_pro(pooler_output1)\n",
    "        x =pooler_output1+pooler_output2\n",
    "        x=self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde662a-cb12-4145-8178-5d66344f8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model loading and setting\n",
    "device = torch.device(\"cuda:0\") \n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "if d_m==\"1024_480\":\n",
    "    model = MyModel1()\n",
    "elif d_m==\"480_1024\":\n",
    "    model = MyModel2()\n",
    "model.to(device)#Model loading\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_all=99999\n",
    "best_auc=0\n",
    "best_acc=0\n",
    "best_epoch=0\n",
    "best_epoch2=0\n",
    "all_fpr = []\n",
    "all_tpr = []\n",
    "all_aucs = []\n",
    "all_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e71a5e-c4ed-45d8-8301-c684e7070e4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Five-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "for fold, (train_indices, valid_indices) in enumerate(kf.split(train_dataset)):\n",
    "    best_auc=0\n",
    "    best_acc=0\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    best_fpr=np.array([])\n",
    "    best_tpr=np.array([])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    if d_m==\"1024_480\":\n",
    "        model = MyModel1()\n",
    "    elif d_m==\"480_1024\":\n",
    "        model = MyModel2()\n",
    "    model.to(device)#Model loading\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rates)\n",
    "    item=0\n",
    "    for epoch in range(50):\n",
    "        item=item+1\n",
    "        for batch_data, batch_labels, batch_data_protbert in train_dataloader:\n",
    "            model.train()\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_data,batch_data_protbert)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        all_labels = []\n",
    "        all_scores = []\n",
    "        model.eval()      \n",
    "        for batch_data, batch_labels, batch_data_protbert in valid_dataloader:\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_data,batch_data_protbert)\n",
    "            probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "            scores = probabilities[:, 1] \n",
    "            all_labels.extend(batch_labels.tolist())\n",
    "            all_scores.extend(scores.tolist())\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_scores)\n",
    "        auc = roc_auc_score(all_labels, all_scores)\n",
    "        correct_predictions = (np.array(all_scores) >= 0.5).astype(int)\n",
    "        acc = np.mean(correct_predictions == np.array(all_labels))\n",
    "        if auc>best_auc:\n",
    "            best_fpr=fpr\n",
    "            best_tpr=tpr\n",
    "            best_auc=auc\n",
    "    all_fpr.append(best_fpr)\n",
    "    all_tpr.append(best_tpr)\n",
    "    all_aucs.append(best_auc)\n",
    "    print(f\"Fold {fold + 1}: AUC = {best_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429901a-a9fa-486e-8ca2-aaaa96eac21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing roc diagrams\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "max_length = max(len(fpr) for fpr in all_fpr)\n",
    "new_all_fpr = []\n",
    "new_all_tpr = []\n",
    "for fpr, tpr in zip(all_fpr, all_tpr):\n",
    "    f = interp1d(np.linspace(0, 1, len(fpr)), fpr)\n",
    "    t = interp1d(np.linspace(0, 1, len(tpr)), tpr)\n",
    "    new_fpr = f(np.linspace(0, 1, max_length))\n",
    "    new_tpr = t(np.linspace(0, 1, max_length))\n",
    "    new_all_fpr.append(new_fpr)\n",
    "    new_all_tpr.append(new_tpr)\n",
    "all_fpr=new_all_fpr\n",
    "all_tpr=new_all_tpr\n",
    "for i in range(len(all_fpr)):\n",
    "    plt.plot(all_fpr[i], all_tpr[i], linestyle='--',lw=1, label=f'Fold {i + 1} (AUC = {all_aucs[i]:.3f})')\n",
    "mean_fpr = np.mean(all_fpr, axis=0)\n",
    "mean_tpr = np.mean(all_tpr, axis=0)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', linestyle='-', lw=1.5, label='Mean ROC (AUC = {:.3f})'.format(np.mean(all_aucs)))\n",
    "# Setting Graphic Properties\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('5_fold_roc.png',dpi=400)# roc image save path\n",
    "plt.show()\n",
    "print(\"AUC for each fold:\", all_aucs)\n",
    "print(\"Mean AUC:\", np.mean(all_aucs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
