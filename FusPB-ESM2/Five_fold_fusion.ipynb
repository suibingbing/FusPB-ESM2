{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a3b3f-3c2d-4bc8-a3f8-09713db4a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import random\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "device = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fd42e-35ab-4a17-a612-25f50b989293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model settings\n",
    "batch_size=32# Setting batchsize\n",
    "learning_rates=0.000065# Setting learning rates\n",
    "model1_name=\"esm2_12\"# Select different versions of the ESM2 model: esm2_6,esm_12,esm_30.\n",
    "model2_name=\"protbert_ur100\"#Selection of different versions of ProBert models: protbert_ur100,protbert_bfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d3c4c-999c-4944-aaf9-5144b3cb66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset definitions\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.sequence, self.label = self.read_file(file)\n",
    "        self.sequence_protbert=self.add_space_between_characters(self.sequence)\n",
    "\n",
    "    def read_file(self,file_path):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        with open(file_path, 'r', newline='') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            next(csv_reader, None) \n",
    "            data = list(csv_reader)\n",
    "            random.seed(42)\n",
    "            random.shuffle(data)\n",
    "            for row in data:\n",
    "                sequences.append(row[0])\n",
    "                labels.append(row[1])\n",
    "        return sequences, labels\n",
    "    \n",
    "    def add_space_between_characters(self,input_list):\n",
    "        new_list = []\n",
    "        for element in input_list:\n",
    "            new_element = ' '.join(element)\n",
    "            new_list.append(new_element)\n",
    "\n",
    "        return new_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample=self.sequence[index]\n",
    "        sample_protbert=self.sequence_protbert[index]\n",
    "        label=int(self.label[index])\n",
    "        return sample, label, sample_protbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005949c5-602f-477a-a35a-fb62fbbc8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training set\n",
    "train_file = 'data/trainCPP.csv'  \n",
    "train_dataset = MyDataset(train_file)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44318f80-8efc-4d2e-95f9-5dcaa3faedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the fusion models\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(MyModel, self).__init__()\n",
    "        if model1_name==\"esm2_30\":\n",
    "            self.model = AutoModel.from_pretrained(\"facebook/esm2_t30_150M_UR50D\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t30_150M_UR50D\")\n",
    "            self.layer=640\n",
    "        elif model1_name==\"esm2_12\":\n",
    "            self.model = AutoModel.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "            self.layer=480\n",
    "        elif model1_name==\"esm2_6\":\n",
    "            self.model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "            self.layer=320\n",
    "        if model2_name==\"protbert_bdf\":\n",
    "            self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\", do_lower_case=False)\n",
    "            self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "        elif model2_name==\"protbert_ur100\":\n",
    "            self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "            self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc_pro = nn.Linear(480, 1024)  \n",
    "        self.fc1 = nn.Linear(1024, 2)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(20, 2)  \n",
    "\n",
    "    def forward(self, inputs,inputs2):\n",
    "        inputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        encoded_input = self.tokenizer_pro(inputs2, padding=True, truncation=True,return_tensors='pt').to(device)\n",
    "        outputs_pro = self.model_pro(**encoded_input)\n",
    "        pooler_output1 = outputs.pooler_output   \n",
    "        pooler_output2=outputs_pro.pooler_output\n",
    "        pooler_output1=self.fc_pro(pooler_output1)\n",
    "        x =pooler_output1+pooler_output2\n",
    "        x=self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca56cd-cab2-4d9b-9ce7-c9d639f5046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model loading and setting\n",
    "device = torch.device(\"cuda:0\") \n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "model = MyModel()\n",
    "model.to(device)#Model loading\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_all=99999\n",
    "best_auc=0\n",
    "all_fpr = []\n",
    "all_tpr = []\n",
    "all_aucs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7b34d-349b-4255-b93d-b4f2707e588b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Five-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "for fold, (train_indices, valid_indices) in enumerate(kf.split(train_dataset)):\n",
    "    best_auc=0\n",
    "    best_acc=0\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    best_fpr=np.array([])\n",
    "    best_tpr=np.array([])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    model = MyModel()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rates)\n",
    "    item=0\n",
    "    for epoch in range(50):\n",
    "        item=item+1\n",
    "        for batch_data, batch_labels, batch_data_protbert in train_dataloader:\n",
    "            model.train()\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_data,batch_data_protbert)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        all_labels = []\n",
    "        all_scores = []\n",
    "        model.eval()      \n",
    "        for batch_data, batch_labels, batch_data_protbert in valid_dataloader:\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_data,batch_data_protbert)\n",
    "            probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "            scores = probabilities[:, 1] \n",
    "            all_labels.extend(batch_labels.tolist())\n",
    "            all_scores.extend(scores.tolist())\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_scores)\n",
    "        auc = roc_auc_score(all_labels, all_scores)\n",
    "        correct_predictions = (np.array(all_scores) >= 0.5).astype(int)\n",
    "        acc = np.mean(correct_predictions == np.array(all_labels))\n",
    "        if auc>best_auc:\n",
    "            best_fpr=fpr\n",
    "            best_tpr=tpr\n",
    "            best_auc=auc\n",
    "    all_fpr.append(best_fpr)\n",
    "    all_tpr.append(best_tpr)\n",
    "    all_aucs.append(best_auc)\n",
    "    print(f\"Fold {fold + 1}: AUC = {best_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1185a-4ff2-4993-baec-209ee4c7ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing roc diagrams\n",
    "plt.figure(figsize=(8, 6))\n",
    "max_length = max(len(fpr) for fpr in all_fpr)\n",
    "new_all_fpr = []\n",
    "new_all_tpr = []\n",
    "for fpr, tpr in zip(all_fpr, all_tpr):\n",
    "    f = interp1d(np.linspace(0, 1, len(fpr)), fpr)\n",
    "    t = interp1d(np.linspace(0, 1, len(tpr)), tpr)\n",
    "    new_fpr = f(np.linspace(0, 1, max_length))\n",
    "    new_tpr = t(np.linspace(0, 1, max_length))\n",
    "    new_all_fpr.append(new_fpr)\n",
    "    new_all_tpr.append(new_tpr)\n",
    "all_fpr=new_all_fpr\n",
    "all_tpr=new_all_tpr\n",
    "for i in range(len(all_fpr)):\n",
    "    plt.plot(all_fpr[i], all_tpr[i], linestyle='--',lw=1, label=f'Fold {i + 1} (AUC = {all_aucs[i]:.3f})')\n",
    "mean_fpr = np.mean(all_fpr, axis=0)\n",
    "mean_tpr = np.mean(all_tpr, axis=0)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', linestyle='-', lw=1.5, label='Mean ROC (AUC = {:.3f})'.format(np.mean(all_aucs)))\n",
    "# Setting Graphic Properties\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('../../autodl-tmp/5fold_probertUR100+esm2_12/5_fold_roc_8.png',dpi=400)# roc image save path\n",
    "plt.show()\n",
    "print(\"AUC for each fold:\", all_aucs)\n",
    "print(\"Mean AUC:\", np.mean(all_aucs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
