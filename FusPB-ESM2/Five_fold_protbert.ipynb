{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f35325-a26f-41a6-8cca-c8ed4a5fad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import random\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc0066-c6ae-4a41-86a3-ea9876cdbb8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32  # Setting batchsize\n",
    "learning_rates=0.000065 # Setting learning rates\n",
    "model_name=\"bert_ur100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d7c2a-4d04-415d-a318-190ae661b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset definitions\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.sequence, self.label = self.read_file(file)\n",
    "        self.sequence_protbert=self.add_space_between_characters(self.sequence)\n",
    "\n",
    "    def read_file(self,file_path):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        with open(file_path, 'r', newline='') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            next(csv_reader, None)  \n",
    "            data = list(csv_reader)\n",
    "            random.seed(42)\n",
    "            random.shuffle(data) \n",
    "            for row in data:\n",
    "                sequences.append(row[0])\n",
    "                labels.append(row[1])\n",
    "        return sequences, labels\n",
    "    \n",
    "    def add_space_between_characters(self,input_list):\n",
    "        new_list = []\n",
    "        for element in input_list:\n",
    "            new_element = ' '.join(element)\n",
    "            new_list.append(new_element)\n",
    "        return new_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        sample=self.sequence[index]\n",
    "        sample_protbert=self.sequence_protbert[index]\n",
    "        label=int(self.label[index])\n",
    "        return sample, label, sample_protbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c228a-2d79-434c-b2be-dce86b260f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training set\n",
    "train_file = 'data/trainCPP.csv' \n",
    "train_dataset = MyDataset(train_file)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf2068-038a-4963-b5e0-fd56b71ab4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the protbert family of models\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\", do_lower_case=False)\n",
    "        self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "        self.fc2 = nn.Linear(1024, 2)  # 输出2个类别的分类结果\n",
    "        self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\", do_lower_case=False)\n",
    "        self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "        if model_name==\"protbert_bdf\":\n",
    "            self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\", do_lower_case=False)\n",
    "            self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "        elif model_name==\"protbert_ur100\":\n",
    "            self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "            self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "    def forward(self, inputs,inputs2):\n",
    "        encoded_input = self.tokenizer_pro(inputs2, padding=True, truncation=True,return_tensors='pt').to(device)\n",
    "        outputs_pro = self.model_pro(**encoded_input)  \n",
    "        pooler_output2=outputs_pro.pooler_output\n",
    "        x=self.fc2(pooler_output2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a4056-7ec9-4b5d-9ec4-1a0fe8bb4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model loading and setting\n",
    "\n",
    "device = torch.device(\"cuda:0\") \n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "model = MyModel()#Model loading\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_all=99999\n",
    "best_auc=0\n",
    "best_acc=0\n",
    "all_fpr = []\n",
    "all_tpr = []\n",
    "all_aucs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea68b66-1f30-4f56-80cb-dba7aa686451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Five-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "for fold, (train_indices, valid_indices) in enumerate(kf.split(train_dataset)):\n",
    "    best_auc=0\n",
    "    best_acc=0\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    best_fpr=np.array([])\n",
    "    best_tpr=np.array([])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    model = MyModel()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rates)# 模型训练\n",
    "    item=0\n",
    "    for epoch in range(50):\n",
    "        for batch_data, batch_labels, batch_data_protbert in train_dataloader:\n",
    "            model.train()\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_data,batch_data_protbert)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            all_labels = []\n",
    "            all_scores = []\n",
    "            model.eval()      \n",
    "            for batch_data, batch_labels, batch_data_protbert in valid_dataloader:\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                outputs = model(batch_data,batch_data_protbert)\n",
    "                probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "                scores = probabilities[:, 1]  \n",
    "                all_labels.extend(batch_labels.tolist())\n",
    "                all_scores.extend(scores.tolist())\n",
    "            fpr, tpr, _ = roc_curve(all_labels, all_scores)\n",
    "            auc = roc_auc_score(all_labels, all_scores)\n",
    "            correct_predictions = (np.array(all_scores) >= 0.5).astype(int)\n",
    "            acc = np.mean(correct_predictions == np.array(all_labels))\n",
    "            if auc>best_auc:\n",
    "                best_fpr=fpr\n",
    "                best_tpr=tpr\n",
    "                best_auc=auc\n",
    "    all_fpr.append(best_fpr)\n",
    "    all_tpr.append(best_tpr)\n",
    "    all_aucs.append(best_auc)\n",
    "    print(f\"Fold {fold + 1}: AUC = {best_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df73462-da3a-4721-96f7-e3485dd72bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drawing roc diagrams\n",
    "plt.figure(figsize=(8, 6))\n",
    "max_length = max(len(fpr) for fpr in all_fpr)\n",
    "new_all_fpr = []\n",
    "new_all_tpr = []\n",
    "for fpr, tpr in zip(all_fpr, all_tpr):\n",
    "    f = interp1d(np.linspace(0, 1, len(fpr)), fpr)\n",
    "    t = interp1d(np.linspace(0, 1, len(tpr)), tpr)\n",
    "    new_fpr = f(np.linspace(0, 1, max_length))\n",
    "    new_tpr = t(np.linspace(0, 1, max_length))\n",
    "    new_all_fpr.append(new_fpr)\n",
    "    new_all_tpr.append(new_tpr)\n",
    "all_fpr=new_all_fpr\n",
    "all_tpr=new_all_tpr\n",
    "for i in range(len(all_fpr)):\n",
    "    plt.plot(all_fpr[i], all_tpr[i], linestyle='--',lw=1, label=f'Fold {i + 1} (AUC = {all_aucs[i]:.3f})')\n",
    "mean_fpr = np.mean(all_fpr, axis=0)\n",
    "mean_tpr = np.mean(all_tpr, axis=0)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', linestyle='-', lw=1.5, label='Mean ROC (AUC = {:.3f})'.format(np.mean(all_aucs)))\n",
    "# Setting Graphic Properties\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('../../autodl-tmp/5fold_esm2_6/5_fold_roc.png',dpi=400)# roc image save path\n",
    "print(\"AUC for each fold:\", all_aucs)\n",
    "print(\"Mean AUC:\", np.mean(all_aucs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
