{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ea3d4-ba1d-449a-8ca3-34f0da67922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0762f-d8fd-462f-800a-c6eb13d7a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of indicators and dataset definitions\n",
    "\n",
    "def calculate_metrics2(labels, scores, threshold):\n",
    "\n",
    "    sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    binary_predictions = [1 if scores[i] >= threshold else 0 for i in sorted_indices]\n",
    "    TP = sum([1 for i in range(len(labels)) if labels[i] == 1 and binary_predictions[i] == 1])\n",
    "    FP = sum([1 for i in range(len(labels)) if labels[i] == 0 and binary_predictions[i] == 1])\n",
    "    TN = sum([1 for i in range(len(labels)) if labels[i] == 0 and binary_predictions[i] == 0])\n",
    "    FN = sum([1 for i in range(len(labels)) if labels[i] == 1 and binary_predictions[i] == 0])\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
    "    specificity = TN / (TN + FP) if TN + FP > 0 else 0.0\n",
    "    sensitivity = recall\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0.0\n",
    "    return recall, specificity, sensitivity, precision\n",
    "\n",
    "\n",
    "def update_best_metrics(a, b, c, recall, specificity, sensitivity, precision, metrics):\n",
    "    d, e, f,recall3, specificity3, sensitivity3, precision3= metrics\n",
    "    updated = False \n",
    "    if a >=d:\n",
    "        d = a\n",
    "        recall3=recall\n",
    "        specificity3=specificity\n",
    "        sensitivity3=sensitivity\n",
    "        precision3=precision\n",
    "        updated = True\n",
    "    if b >= e:\n",
    "        e = b\n",
    "        updated = True\n",
    "    if f >= c:\n",
    "        c = f\n",
    "        updated = True\n",
    "    return (d, e, c,recall3, specificity3, sensitivity3, precision3), updated\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.sequence, self.label = self.read_file(file)\n",
    "        self.sequence_protbert=self.add_space_between_characters(self.sequence)\n",
    "        \n",
    "    def read_file(self,file_path):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        with open(file_path, 'r', newline='') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            next(csv_reader, None) \n",
    "            for row in csv_reader:\n",
    "                sequences.append(row[0])\n",
    "                labels.append(row[1])\n",
    "        return sequences, labels\n",
    "    \n",
    "    def add_space_between_characters(self,input_list):\n",
    "        new_list = []\n",
    "        for element in input_list:\n",
    "            new_element = ' '.join(element)\n",
    "            new_list.append(new_element)\n",
    "        return new_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample=self.sequence[index]\n",
    "        sample_protbert=self.sequence_protbert[index]\n",
    "        label=int(self.label[index])\n",
    "        return sample, label, sample_protbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1508eb-5ed6-4375-87ea-e6cc2f71584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FusPB-ESM2 model Definition\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "        self.tokenizer_pro = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "        self.model_pro = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc_pro = nn.Linear(480, 1024)  \n",
    "        self.fc1 = nn.Linear(1024, 2)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(20, 2)  \n",
    "\n",
    "    def forward(self, inputs,inputs2):\n",
    "        inputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        encoded_input = self.tokenizer_pro(inputs2, padding=True, truncation=True,return_tensors='pt').to(device)\n",
    "        outputs_pro = self.model_pro(**encoded_input)\n",
    "        pooler_output1 = outputs.pooler_output   \n",
    "        pooler_output2=outputs_pro.pooler_output\n",
    "        pooler_output1=self.fc_pro(pooler_output1)\n",
    "        x =pooler_output1+pooler_output2\n",
    "        x=self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49a38e-36eb-4ec3-bbd9-e994a89aa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset\n",
    "\n",
    "train_file = 'data/trainCPP.csv'  #Read training set\n",
    "test_file = 'data/testCPP.csv'  #Read independent test set\n",
    "train_dataset = MyDataset(train_file)\n",
    "test_dataset = MyDataset(test_file)\n",
    "batch_size = 32  #Setting batchsize\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f09926-d3b9-4c8b-87ed-dc739d1f4d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model loading and setting\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random_seed = 42\n",
    "loss_all=99999\n",
    "metrics = (0, 0, 0,0,0,0,0)  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = MyModel()#Model loading\n",
    "model.to(device)\n",
    "learning_rates=0.00006525 #Setting learning rates\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9eedc-9a1e-4f88-b3b1-a57589f0953d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model training and evaluation\n",
    "\n",
    "for epoch in range(50):\n",
    "    item=0\n",
    "    print(\"epoch\",epoch)\n",
    "    for batch_data, batch_labels, batch_data_protbert in train_dataloader:\n",
    "        item=item+1\n",
    "        model.train()\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        outputs = model(batch_data,batch_data_protbert)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "    pre=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for batch_data, batch_labels, batch_data_protbert in test_dataloader:\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_data,batch_data_protbert)\n",
    "            probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "            scores = probabilities[:, 1]  \n",
    "            all_labels.extend(batch_labels.tolist())\n",
    "            all_scores.extend(scores.tolist())\n",
    "            predicted_labels = scores >= 0.5 \n",
    "            pre.extend(predicted_labels.tolist())\n",
    "            correct_predictions += (predicted_labels == batch_labels).sum().item()\n",
    "            total_predictions += batch_labels.size(0)\n",
    "    acc = correct_predictions / total_predictions\n",
    "    auc = roc_auc_score(all_labels, all_scores)\n",
    "    mcc = matthews_corrcoef(all_labels, pre)\n",
    "    recall, specificity, sensitivity, precision = calculate_metrics2(all_labels, all_scores, 0.5)\n",
    "    current_metrics = (acc, auc, mcc,recall, specificity, sensitivity, precision) \n",
    "    metrics, updated = update_best_metrics(*current_metrics, metrics)\n",
    "print(f\"BEST_AUC: {metrics[1]:.3f}\",f\"ACC: {metrics[0]:.3f}\", f\"MCC: {metrics[2]:.3f}\",f\"specificity: {metrics[4]:.3f}\", f\"sensitivity: {metrics[5]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
